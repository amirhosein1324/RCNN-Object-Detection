{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import gdown\n",
        "import os\n",
        "import zipfile\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "sw4Yh3hd4lwJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_coco_data():\n",
        "    if not os.path.exists(\"coco_data\"):\n",
        "        os.makedirs(\"coco_data\")\n",
        "\n",
        "    img_url = 'http://images.cocodataset.org/zips/val2017.zip'\n",
        "    ann_url = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "\n",
        "    print(\"Downloading COCO Images...\")\n",
        "    gdown.download(img_url, 'coco_data/val2017.zip', quiet=False)\n",
        "\n",
        "    print(\"Downloading COCO Annotations...\")\n",
        "    gdown.download(ann_url, 'coco_data/annotations.zip', quiet=False)\n",
        "\n",
        "\n",
        "    print(\"Unzipping files...\")\n",
        "    with zipfile.ZipFile('coco_data/val2017.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('coco_data')\n",
        "    with zipfile.ZipFile('coco_data/annotations.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('coco_data')\n",
        "\n",
        "    print(\"Dataset Ready.\")"
      ],
      "metadata": {
        "id": "Dqk-7j2l4mgW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"coco_data/val2017\"):\n",
        "    download_coco_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sEe43tC4mdB",
        "outputId": "2e52bada-e5b6-4b68-fe96-06842289fbb7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: http://images.cocodataset.org/zips/val2017.zip\n",
            "To: /content/coco_data/val2017.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading COCO Images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 816M/816M [00:14<00:00, 55.6MB/s]\n",
            "Downloading...\n",
            "From: http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "To: /content/coco_data/annotations.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading COCO Annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253M/253M [00:04<00:00, 52.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping files...\n",
            "Dataset Ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class COCODataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, annotation, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        from pycocotools.coco import COCO\n",
        "        self.coco = COCO(annotation)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        coco = self.coco\n",
        "        img_id = self.ids[index]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        from PIL import Image\n",
        "        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
        "\n",
        "        num_objs = len(coco_annotation)\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(num_objs):\n",
        "            xmin = coco_annotation[i]['bbox'][0]\n",
        "            ymin = coco_annotation[i]['bbox'][1]\n",
        "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(coco_annotation[i]['category_id'])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([img_id])\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "metadata": {
        "id": "I7yK0P9E4y4Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(num_classes):\n",
        "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "btire-4o43Jn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Q7EVBg58lK",
        "outputId": "77f2f889-627c-4861-d97e-192edd28be5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_transform():\n",
        "    transforms = []\n",
        "    transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(transforms)\n",
        "\n",
        "dataset = COCODataset(root='coco_data/val2017',\n",
        "                      annotation='coco_data/annotations/instances_val2017.json',\n",
        "                      transforms=get_transform())\n",
        "\n",
        "dataset_subset = Subset(dataset, indices=range(100))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "data_loader = DataLoader(dataset_subset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "model = get_model(num_classes=91)\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-VxRH4R482q",
        "outputId": "8ff6c282-9bbe-40d9-f833-232c52897c94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.47s)\n",
            "creating index...\n",
            "index created!\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160M/160M [00:01<00:00, 134MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "print(f\"Starting training on device: {device}\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    i = 0\n",
        "    for imgs, annotations in tqdm.tqdm(data_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        i += 1\n",
        "        imgs = list(img.to(device) for img in imgs)\n",
        "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "\n",
        "        loss_dict = model(imgs, annotations)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += losses.item()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch: {epoch+1}, Step: {i}, Loss: {losses.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Complete. Average Loss: {epoch_loss/i:.4f}\")\n",
        "\n",
        "print(\"Training Finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhftKXSz5H78",
        "outputId": "51ce7c2a-1b02-4565-a4c7-714091f35859"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|████      | 10/25 [00:13<00:16,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Step: 10, Loss: 1.3093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|████████  | 20/25 [00:26<00:06,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Step: 20, Loss: 1.7975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 25/25 [00:32<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Complete. Average Loss: 1.8819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  40%|████      | 10/25 [00:13<00:20,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Step: 10, Loss: 1.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|████████  | 20/25 [00:26<00:05,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Step: 20, Loss: 1.4657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 25/25 [00:32<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Complete. Average Loss: 1.1844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  40%|████      | 10/25 [00:13<00:19,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Step: 10, Loss: 1.9182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  80%|████████  | 20/25 [00:27<00:06,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Step: 20, Loss: 0.6429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 25/25 [00:34<00:00,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Complete. Average Loss: 1.1037\n",
            "Training Finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9hb9OXi6UfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}